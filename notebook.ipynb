{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from sklearn.utils import shuffle\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, csv_file, device):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.device = device\n",
    "        # Add any necessary data preprocessing or feature extraction here\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {\n",
    "            'data': torch.tensor(self.data.iloc[idx, 1:].values, dtype=torch.float64, device=self.device),\n",
    "            'label': torch.tensor(self.data.iloc[idx, 0], dtype=torch.long, device=self.device)\n",
    "        }\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = MyDataset(\"../input/fashionmnist/fashion-mnist_train.csv\", device)\n",
    "test = MyDataset(\"../input/fashionmnist/fashion-mnist_test.csv\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = []\n",
    "train_data = []\n",
    "for i in range(len(train)):\n",
    "    sample = train[i]\n",
    "    train_label.append(sample['label'])\n",
    "    train_data.append(sample['data'])\n",
    "\n",
    "test_label = []\n",
    "test_data = []\n",
    "for i in range(len(test)):\n",
    "    sample = test[i]\n",
    "    test_label.append(sample['label'])\n",
    "    test_data.append(sample['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(data, label):\n",
    "    num_data = len(data)\n",
    "    num_batches = num_data // 32\n",
    "    batches_x = []\n",
    "    batches_y = []\n",
    "    shuffled_indices = np.random.permutation(num_data)\n",
    "    \n",
    "    for i in range(0, num_data, num_batches):\n",
    "        batch_indices = shuffled_indices[i:i+32]\n",
    "        batch_x = torch.stack([data[idx] for idx in batch_indices]).to(device)\n",
    "#         batch_x = batch_x.double()\n",
    "        batch_y = torch.stack([label[idx] for idx in batch_indices]).to(device)\n",
    "#         batch_y = batch_y.double()\n",
    "        batches_x.append(batch_x)\n",
    "        batches_y.append(batch_y)\n",
    "    return batches_x, batches_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(784, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(out, y):\n",
    "    y_pred = torch.argmax(out)\n",
    "    return (y_pred == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(device)\n",
    "# model = model.double()\n",
    "model.to(device)\n",
    "learning_rate = 1e-3\n",
    "n_epochs = 10\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate) \n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_tensor = torch.stack(train_data)\n",
    "train_label_tensor = torch.stack(train_label)\n",
    "\n",
    "print(train_data_tensor.shape)\n",
    "print(train_label_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = create_batches(train_data, train_label)\n",
    "data_loader = DataLoader(train, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    idx = 0\n",
    "    for batch in data_loader:\n",
    "        data = batch[0]\n",
    "        label = batch[1]\n",
    "        out = model.forward(data.to(model.net[0].weight.dtype))\n",
    "#         loss = criterion(out, batch_y.to(torch.long))\n",
    "        loss = criterion(out, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if (idx % 100 == 0):\n",
    "            t = int(time.time() - start_time); \n",
    "            t_str = '%2dh %2dm %2ds' % (int(t / 3600), int((t % 3600) / 60), t % 60)\n",
    "            print(f\"Time: {t_str} step {idx}: loss: {loss:.4f}\")\n",
    "        idx += 1\n",
    "    print(f\"Epoch: {epoch+1} complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "i = 0 \n",
    "correct = 0\n",
    "softmax = nn.Softmax()\n",
    "for batch_x, batch_y in zip(X, Y):\n",
    "    out = model.forward(batch_x.to(model.net[0].weight.dtype))\n",
    "    a = softmax(out)\n",
    "    loss = criterion(out, batch_y.to(torch.long))\n",
    "    for j in range(out.shape[0]):\n",
    "        result = torch.argmax(a[j,:])\n",
    "        correct += (result == batch_y[j])\n",
    "    \n",
    "    if (i % 10 == 0):\n",
    "        print(f\"Iter: {i+1} loss: {loss} accuracy: {correct/(32*(i+1))}\")\n",
    "        \n",
    "    i += 1\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XV, YV = create_batches(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "i = 0 \n",
    "correct = 0\n",
    "softmax = nn.Softmax()\n",
    "for batch_x, batch_y in zip(XV, YV):\n",
    "    out = model.forward(batch_x.to(model.net[0].weight.dtype))\n",
    "    a = softmax(out)\n",
    "    loss = criterion(out, batch_y.to(torch.long))\n",
    "    for j in range(out.shape[0]):\n",
    "        result = torch.argmax(a[j,:])\n",
    "        correct += (result == batch_y[j])\n",
    "    \n",
    "    if (i % 10 == 0):\n",
    "        print(f\"Iter: {i+1} loss: {loss} accuracy: {correct/(32*(i+1))}\")\n",
    "        \n",
    "    i += 1\n",
    "model.train()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
